# WiDS 5.O

This repository presents my work completed as part of **WiDS (Winter in Data Science) 5.O**, under the project **UID: 40 â€“ Speech to Text Engine**.

The repository documents the weekly progress and learning outcomes achieved throughout the program.

---

## ðŸ“… Week 1 â€” Foundations of Natural Language Processing

### Topics Covered
- Core concepts of NLP  
- Tokenization and stopword handling  
- Stemming and lemmatization methods  
- N-gram based text representation  
- Fundamental text preprocessing techniques  

---

## ðŸ“… Week 2 â€” Neural Networks for NLP

### Topics Covered
- Word embedding techniques (Word2Vec, GloVe)  
- Bag-of-Words and TF-IDF approaches  
- Sentiment classification using LSTM models  
- Visualization of embeddings using PCA and t-SNE  
- Comparative evaluation of NLP models  

---

## ðŸ“… Week 3 â€” Transformer-Based NLP Models

### Topics Covered
- Working principles of transformers and self-attention  
- Comparison between BERT, GPT, and Encoderâ€“Decoder architectures  
- Subword tokenization techniques (WordPiece, BPE, SentencePiece)  
- Fine-tuning transformer models for classification tasks  
- Leveraging Hugging Face pipelines  
- Abstractive text summarization with BART  

---

## ðŸ“… Week 4 â€” Fundamentals of Speech Processing

### Topics Covered
- Digital representation of speech signals  
- Sampling, quantization, and frame segmentation  
- Spectrogram-based timeâ€“frequency analysis  
- Mel scale fundamentals and Mel spectrogram computation  
- MFCC-based feature extraction  
- Traditional versus deep learning speech recognition methods  
- Audio preprocessing workflow  
- Basic keyword spotting concepts  

---

## ðŸ“… Week 5 â€” Developing a Speech-to-Text System

### Topics Covered
- Introduction to Speech-to-Text (STT) technology  
- Complete STT processing pipelines  
- Use of pretrained speech recognition models  
- Architectural overview of Whisper and Wav2Vec 2.0  
- Speech data preparation and preprocessing  
- Fine-tuning pretrained STT models  
- Model performance evaluation using Word Error Rate (WER)  

---

## âœ… Notes
- The work follows the structured weekly plan of the WiDS program  
- Implementations focus on conceptual clarity and learning outcomes  
- Lightweight models and datasets are used to ensure efficient execution

---


